[TOC]

# 深度学习

作业：

1. 运行猫脸识别实验
2. 求网络中任一节点的偏导数？
3. 文本分类

## 1. 概论及入门

### 1.1 概念辨析

- 下图表示了人工智能、机器学习、深度学习三者可以被简单描述为嵌套关系：
  - **人工智能**是最早出现的，范围也最广。
  - 随后出现的是**机器学习**。
  - 最内侧是**深度学习**，也是当今人工智能大爆炸的核心驱动。

![image-20181025185359354](images/image-20181025185359354.png)

- 简单来说，**机器学习**是实现**人工智能**的方法；
- **深度学习**，是实现机器学习的技术之一。
- 也可以说，**机器学习是人工智能的子集，而深度学习是机器学习的子集**。

#### 人工智能

- 人工智能，是计算机科学的一个分支，是一门研究机器智能的学科，即用人工的方法和技术来研制智能机器或智能系统，以此来模仿、延伸和扩展人的智能。
- 人工智能的主要任务是建立智能信息处理理论，使计算机系统拥有近似于人类的智能行为。

#### 机器学习

- 定义：如果一个程序可以在任务T上，随着经验E的增加，效果P也可以随之增加，则称这个程序可以从经验中学习。
- 机器学习是一种“训练”算法的方式，目的是使机器能够向算法传送大量的数据，并允许算法进行自我调整和改进。
- 而不是利用具有特定指令的编码软件例程来完成指定的任务。
- 它要在大数据中寻找一些“模式”，然后在没有过多的人为参与的情况下，用这些模式来预测结果，而这些模式在普通的统计分析中是看不到的。机器学习的传统算法包括决策树学习、推导逻辑规划、聚类、分类、回归、贝叶斯网络和神经网络等等。
- 深度学习自动完成了特征选择，大大增加了模型的能力和工程效率。
- 传统机器学面临特征选择等问题很难解决。传统机器学习最关键的问题是必须依赖给定数据的表示，而实际上，在大部分任务中我们很难知道应该提取哪些特征。例如我们想要在一堆动物的图片中辨认出猫，试图通过判断胡须、耳朵、尾巴等元素存在与否来辨认，但如果照片中存在很多遮挡物，或是猫的姿势改变等等，都会影响机器识别特征。找不到一个合理的方法提取数据，这就使问题变得棘手。
  直到深度学习的出现，通过其他较简单的表示来表达复杂的表示，解决了机器学习的核心问题。

#### 深度学习

- 相比于传统的机器学习，深度学习不再需要人工的方式进行特征提取，而是自动从简单特征中提取、组合更复杂的特征。
- 深度学习可以理解为传统神经网络的拓展,每一层就相当于在某个抽象级别抽取特征。

![image-20181025192317651](images/image-20181025192317651.png)

- 深度学习是基于多层神经网络的，以海量数据为输入的，规则自学习的方法
- 然而为什么一定是深度？深层神经网络比浅层好在哪里？
  - 一方面，深度学习在重复利用中间层计算单元的情况下，大大减少了参数的设定。
    - 在过去的神经网络中，人们对经验的利用，靠人类自己完成。在深度学习中，经验以数据形式存在。
  - 另一方面，深度学习通过学习一种深层非线性网络结构，只需简单的网络结构即可实现复杂函数的逼近，并展现了强大的从大量无标注样本集中学习数据集本质特征的能力。
    - 深度学习可以获得更好的方法表示数据的特征，同时由于模型的层次深、表达能力强，因此有能力处理大规模数据。对于图像、语音这种直接特征不明显（需要手工设计且很多没有直观的物理含义）的问题，深度模型能够在大规模训练数据上取得更好的效果。
- 值的注意的是，深度学习不是万能的，像很多其他方法一样，它需要结合特定领域的先验知识，需要和其他方法结合才能得到最好的结果。
- 此外，类似于神经网络，深度学习的另一局限性是可解释性不强，像个“黑箱子”一样难以解释为什么能取得好的效果，以及不知如何有针对性地去具体改进，而这有可能成为前进过程中的阻碍。

### 1.2 发展历程

#### 神经网络

- **人工神经网络（Artificial Neural Networks，简写为ANNs）**也简称为**神经网络（NNs）**或称作连接模型（Connection Model），它是一种模仿动物神经网络行为特征，进行分布式并行信息处理的算法数学模型。这种网络依靠系统的复杂程度，通过调整内部大量节点之间相互连接的关系，从而达到处理信息的目的。
- 神经网络的第一次高潮是感知机带来的。1957年，Frank Rosenblatt提出了感知机的概念，成为日后发展神经网络和支持向量机（Support Vector Machine, SVM）的基础。
- 第二次高潮，突破性进展：1982年，加州理工的生物物理学家John Hopfield提出了一种反馈型神经网络（Hopfile网络），这一网络成果的解决了一些识别和约束优化的问题。
  - 在1986年，反向传播算法（BP算法）在神经网络模型上应用。在做诸如形状识别之类的简单工作时，效率大大的提高了。
  - 计算机运行速度提高，使一层以上的神经网络进入了实用阶段。
- 第三次高潮，深度学习适应时代发展成为了主流。
  - 更优化的算法
  - 更高性能的计算能力：深度学习崛起的另一条件是强大计算能力的出现，现在进行深度学习研究使用的都是GPU，使用GPU集群可以将原来一个月才能训练出的网络，加速到几个小时，时间上的大幅缩短使得研究人员训练了大量的网络。
  - 更大的数据集：大数据。相较传统的神经网络，尽管在算法上我们确实简化了深度架构的训练，但最重要的进展是我们有了成功训练这些算法所需的资源。可以说人工智能只有在数据的驱动下，才能实现深度学习、不断迭代模型，变得越来越智能。

### 1.3 应用场景

#### 图像与视觉

- 人脸识别：深度学习帮助人们实现了人脸识别中的人脸比对，即得到一张人脸，与数据库里的人脸进行比对；或同时给两张人脸，判断是不是同一个人。
- 物体检测：深度学习在物体检测方面也取得了非常好的成果。2014年的Region CNN算法，基本思想是首先用一个非深度的方法，在图像中提取可能是物体的图形块，然后深度学习算法根据这些图像块，判断属性和一个具体物体的位置。

#### 语音技术

- 语音搜索：搜索内容直接以语音的方式输入，让搜索更加高效。
-  同声传译：微软公司和科大讯飞均基于深度学习开发出了同声传译系统，实现了巨大的技术突破。
-  智能家居：通过远场语音识别技术，可以让用户，即使在三至五米的距离，也可对智能家居进行语音操作。

#### 自然语言处理

- 文本生成：微软推出了可以自己写诗的程序，通过“阅读”大量的诗集，学会了自己写诗，甚至逐渐形成了自己文风。
- 语言翻译：深度学习在自然语言处理领域的成功应用，使得机器在语义刻画方面取得了突破的成就，百度翻译、谷歌翻译等均实现了高精确度的多语言转换。
- 聊天机器人：基于深度学习技术，很多大型互联网公司都陆续推出了相关产品，苹果的Siri、微软的“小冰”、百度的“小度”等等。为用户提供了生活便利以及情感陪护。

#### 个性化推荐

- 个性化推荐是大数据和深度学习时代的重要产物。
- 传统的推荐类型有基于内容过滤推荐和协同过滤的局限性。
  - 基于内容推荐主要为用户推荐其感兴趣商品的相似商品，缺少用户评价信息的利用，并且不能有效为新用户推荐。
  - 协同过滤推荐计算目标用户与其他用户的相似度，主要预测目标用户对特定商品的喜好程度。可以为用户推荐其未见过的产品，然而对于历史数据稀疏的用户一样难以起到作用。
- 个性化推荐系统应用非常广泛。
- 推荐系统通过对用户行为和商品属性进行分析、挖掘，发现用户的个性化需求与兴趣特点，将用户可能感兴趣的信息或商品推荐给用户。
- 推荐系统不同于搜索引擎根据用户需求被动返回信息的运行过程，它根据用户历史行为主动为用户提供精准的推荐信息。

### 1.4 常见的深度学习网络结构

#### 全连接网络（FC）

- 全连接网络结构（FC）是最基本的神经网络/深度神经网络层，它认为每一层的输入都与上一层的输出有关。

- 常规神经网络一般**用于依赖所有特征的简单场景**，比如说本章的房价预测模型和在线广告推荐模型使用的都是相对标准的全连接神经网络。

![image-20181025194654168](images/image-20181025194654168.png)

#### 卷积神经网络（CNN）

- 卷积神经网络（CNN），是一种专门用来**处理具有类似网格结构的数据**的神经网络，*例如图像数据（可以看作二维的像素网格）*。
- 它与FC不同的地方在于，**CNN的上下层神经元并不都能直接连接，而是通过“卷积核”作为中介，通过“核”的共享大大减少了隐含层的参数。**
- 通常用三个主要类型的层去构建CNN结构，包括**卷积层（Convolutional Layer)**、**池化层（Pooling Layer）**和**全连接层（FC)**。
- 卷积网络在诸多应用领域有很好的应用效果，特别是在大型图像处理的场景表现格外出色。![image-20181025195010543](images/image-20181025195010543.png)



#### 循环神经网络（RNN）

- 就像CNN是专门用于处理网格化的数据（如一个图像）的神经网络，RNN是一种用于**处理序列数据**的神经网络。
- 例如音频中含有时间成分，因此音频可以被表示为一维时间序列；语言中的单词都是逐个出现的，因此语言的表示方式也是序列数据。RNN在机器翻译、语音识别等领域均中有非常好的表现。

![image-20181025195109571](images/image-20181025195109571.png)



### 1.5 机器学习回顾

#### 机器学习的典型过程

- 输入训练数据，利用特定的机器学习方法建立估计函数。得到函数后向这一模型输入测试数据，函数有能力对没有见过的数据进行正确估计，这就是机器学习的过程。



![image-20181025195331569](images/image-20181025195331569.png)

### 1.6 深度学习框架

#### 框架的作用

- 简化计算图的搭建

  - 计算图（computational graph）可以看作是一种描述函数的语言。图中的结点代表函数的输入，边代表这个函数的操作。计算图本质上是一个有向无环图，它可以被用于大部分基础表达式建模。
  - 在深度学习框架中包含许多张量和基于张量的各种操作，随着操作种类的增多，多个操作中间的执行关系变得十分复杂。计算图可以更加精确的描述网络中的参数传播过程，而深度学习框架可以帮你很容易的搭建计算图。这是人们使用深度学习框架进行开发的一个重要原因。

- 高效运行

  - 深度学习框架的另一个重要的优势是它具有灵活的移植性，可以将同一份代码几乎不经过修改地部署到GPU或CPU上，程序员不必将精力消耗在处理内存转移等问题上。

- 简化偏导计算

  - 深度学习框架的另一个好处是让求导计算变得更加简便。在深度学习的模型搭建过程中，不可避免的要计算损失函数，这就需要不停地做微分计算。有了深度学习框架，程序员不再需要自己反复编写微分计算的复杂代码。

  - 神经网络可以被视为由许多非线性过程组成的复杂函数体，而计算图则以模块化的方式完整表达了这一函数体的内部逻辑关系，因此对这一复杂函数体求模型梯度就变成了在计算图中简单地从输入到输出进行一次完整遍历的过程。

  - 相比与传统的微分计算，这一方法大大简化了计算过程。自2012年后，绝大多数的深度学习框架都选择了基于计算图的声明式求解。用计算图做微分求解过程如下图所示。

    ![image-20181026121118714](images/image-20181026121118714.png)

#### 常见框架

- 目前开源的深度框架有许多，各种框架的侧重点也不尽相同，使用者可以根据自己的需求以及使用习惯进行选择。常见的深度学习框架主要有：PaddlePaddle、TensorFlow、Caffe2、PyTorch、MXNet、CNDK等等，各框架的名称及开发公司如下表所示。

![image-20181026121829277](images/image-20181026121829277.png)

## 2. 线性回归模型

> 实验：AIStudio中的房价预测实验。

- 线性回归是机器学习中最简单也是最重要的模型之一，其模型建立同样遵循上图流程：获取数据、数据预处理、训练模型、应用模型。

- 回归模型可以理解为：存在一个点集，用一条曲线去拟合它分布的过程。如果**拟合曲线是一条直线，则称为线性回归**。如果是一条**二次曲线，则被称为二次回归**。线性回归是回归模型中最简单的一种。

- 线性回归中的几个重要概念
  - 假设函数
  - 损失函数
  - 优化算法

### 2.1 重要概念

#### a. 假设函数

- 假设函数是指，用数学的方法**描述自变量和因变量之间的关系**，它们之间可以是一个线性函数或非线性函数。

#### b. 损失函数

- 损失函数是指，用数学的方法衡量**假设函数预测结果与真实值之间的误差。**这个差距越小预测越准确，而算法的任务就是使这个差距越来越小。

- 损失函数的选择需要具体问题具体分析，在不同问题场景下采用不同的函数。通常情况下，会将损失函数定义为平方损失函数（Quadratic Loss Function）。在本次线性回归中，使用的是**均方差（Mean Squared Error）**来衡量:
  $$
  MSE=\frac{1}{n}\sum_{i=1}^{n}(\hat{Y_i}-Y_i)^2
  $$



#### c. 优化算法

- 优化算法决定了一个模型的精度和运算速度，本次线性回归实例中使用了**梯度下降法**进行优化。

##### c.i. 梯度下降

- 假设损失函数为 $J(a,b)$ ，它可以理解为变量 $w$ 和 $b$ 的函数。算法的最终目标是找到损失函数的最小值。而这个寻找过程就是不断地微调变量w和b的值，一步一步地试出这个最小值。而试的方法就是沿着梯度方向逐步移动。

- 应用梯度下降算法，首先需要初始化参数 $w$ 和 $b$ 。一般情况下，深度学习模型中的和应该初始化为一个很小的数，逼近0但是非0。因为 $J(w,b)$ 是凸函数，所以无论初始化在曲面上的哪一点，最终都会收敛到同一点或者相近的点。

- 一旦初始化好 $w$ 和 $b$ 之后，就可以开始迭代过程了。所谓的迭代过程就是从初始点沿着曲面朝着下降最快的方向一步一步地移动。经过多次迭代，最终收敛到全局最优解或者接近全局最优解。

![image-20181025230644408](images/image-20181025230644408.png)

- 为了简化说明，将参数 $b$ 暂时去掉，只考虑参数 $w$ ，这时损失函数变成 $J(w,b)$ 。整个梯度下降过程可以表示为重复如下步骤：
  $$
  w_i:=w_i-\alpha\frac{\partial}{\partial w_i}J(w_i)
  $$

- 以上步骤就是重复对参数进行更新操作，其中 **$\alpha$ 表示学习率**。学习率也是深度学习中的一个重要概念。**学习率可以理解为每次迭代时圆点移动的步长**，**它决定了梯度下降的速率和稳定性**。

### 2.2 概括过程

#### 1.数据处理

- 用线性回归模型预测目标的第一步是进行数据处理。

##### a. 归一化数据

- 接下来就是要对数据进行归一化。一般而言，如果样本有多个属性，那么各维属性的取值范围差异会很大，这就要用到一个常见的操作——**归一化（normalization）**了。归一化的目标是把各位属性的取值范围放缩到差不多的区间，例如[-0.5, 0.5]。这里我们使用一种很常见的操作方法：**减掉均值，然后除以原取值范围。**
- 归一化的原因：
  - 过大或过小的数值范围会导致计算时的浮点上溢或下溢。
  - 不同的数值范围会导致不同属性对模型的重要性不同（至少在训练的初始阶段如此），而这个隐含的假设常常是不合理的。这会对优化的过程造成困难，使训练时间大大加长。
  - 很多的机器学习技巧/模型（例如L1，L2正则项，向量空间模型-Vector Space Model）都基于这样的假设：所有的属性取值都差不多是以0为均值且取值范围相近的。

##### b. 分割数据集

- 将原始数据处理为可用数据后，为了评估模型的好坏，我们将数据分成两份：训练集和测试集。
  - 训练集数据用于调整模型的参数，即进行模型的训练，模型在这份数据集上的误差被称为**训练误差**；
  - 测试集数据被用来测试，模型在这份数据集上的误差被称为**测试误差**。
- 分割数据的比例要考虑到两个因素：
  - 更多的训练数据会降低参数估计的方差，从而得到更可信的模型；
  - 而更多的测试数据会降低测试误差的方差，从而得到更可信的测试误差。

#### 2. 模型概览

- 处理好数据后，就可以开始为模型设计假设函数和损失函数了。

##### a. 模型训练

定义好模型结构之后，我们要通过以下几个步骤进行模型训练：

- 初始化参数，其中包括权重a和偏置b，对其进行初始化（如0均值，1方差）。
- 从当前值开始计算模型输出值和损失函数。
- 利用梯度下降的方法处理损失函数，在寻找损失函数极小值的过程中依次更新模型中的参数。
- 重复2~3步骤，直至网络训练误差达到规定的程度或训练轮次达到设定值。

##### b. 效果展示

右面的散点图展示了使用模型对部分房屋价格进行的预测。其中，每个点的横坐标表示同一类房屋真实价格的中位数，纵坐标表示线性回归模型根据特征预测的结果，当二者值完全相等的时候就会落在直线上。所以模型预测得越准确，则点离直线越近。

可以看出预测结果还是比较不错的，散点基本落在了直线周围。

### 2.3 fluid训练步骤

fluid训练模型的基本步骤:

- 配置网络结构：
- 定义成本函数avg_cost
- 定义优化器optimizer
- 获取训练数据
- 定义运算场所(place)和执行器(exe)
- 提供数据(feeder)
- 执行训练(exe.run)
- 预测infer()并输出拟合图像

练习中的许多参数可以作调整，例如修改学习率会对模型结果产生很大影响，大家可以在本练习或者后面的练习中多做些尝试。

## 3. Logistic回归模型

- 典型的深度学习的计算过程包含3个过程
  - 前向传播
  - 后向传播
  - 梯度下降

- 计算过程内部有先后部分

### Sigmoid()函数：

*Sigmoid*函数主要作用就是把某实数映射到区间*(0,1)*内。

## 推荐算法

### 传统推荐方法

#### 基于内容的推荐(Content-based Recommendation)

#### 协同过滤推荐(Collaborative Filtering Recommendation)

#### 混合推荐(Hybrid Recommendation)

### 深度学习推荐方法

#### YouTube深度神经网络推荐系统

#### 融合推荐系统

==（详见：深度学习-推荐算法.pdf）==

